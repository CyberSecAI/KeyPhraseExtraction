#!/usr/bin/env python3
"""
JSON Fix Script for CVE Keyphrases

This script fixes common JSON formatting issues in keyphrase files that were
generated by AI models but contain malformed structures like nested arrays,
extra quotes, or improper string formatting.

Common patterns fixed:
1. Array fields that should be strings: ["item1", "item2"] -> "item1, item2"
2. Malformed strings with extra quotes: "['item1', 'item2']" -> "item1, item2"
3. Nested structures in string fields
4. Mixed array/string formatting issues

Author: CVE Keyphrase Extraction System
"""

import json
import os
import re
import argparse
import logging
from pathlib import Path
from typing import Dict, Any, List, Union
from datetime import datetime
import shutil

class JSONFixer:
    """Fixes malformed JSON keyphrase files."""
    
    def __init__(self, input_dir: str, output_dir: str, log_level: str = "INFO"):
        """Initialize the JSON fixer.
        
        Args:
            input_dir: Directory containing invalid JSON files
            output_dir: Directory to save fixed JSON files
            log_level: Logging level (DEBUG, INFO, WARNING, ERROR)
        """
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.log_level = log_level
        
        # Create output directory
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Setup logging
        self._setup_logging()
        
        # Required keyphrase fields
        self.required_fields = {
            "rootcause", "weakness", "impact", "vector", 
            "attacker", "product", "version", "component"
        }
        
        # Statistics
        self.stats = {
            "processed": 0,
            "fixed": 0,
            "failed": 0,
            "skipped": 0
        }
        
    def _setup_logging(self):
        """Setup logging configuration."""
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)
        
        logging.basicConfig(
            level=getattr(logging, self.log_level.upper()),
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_dir / "json_fix.log"),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def _normalize_field_value(self, value: Any, field_name: str) -> str:
        """Normalize a field value to a string, handling various malformed patterns.
        
        Args:
            value: The field value to normalize
            field_name: Name of the field for logging
            
        Returns:
            Normalized string value
        """
        if value is None:
            return ""
            
        # If already a string, check for malformed patterns
        if isinstance(value, str):
            # Remove extra quotes and brackets from malformed strings
            # Pattern: "['item1', 'item2']" or "['item']"
            pattern1 = r"^\[(['\"][^'\"]*['\"](?:\s*,\s*['\"][^'\"]*['\"])*)\]$"
            match = re.match(pattern1, value.strip())
            if match:
                # Extract items and clean quotes
                items_str = match.group(1)
                items = re.findall(r"['\"]([^'\"]*)['\"]", items_str)
                result = ", ".join(items)
                self.logger.debug(f"Fixed malformed string pattern in {field_name}: {value} -> {result}")
                return result
                
            # Pattern: ["item1", "item2"] as string (sometimes happens)
            pattern2 = r'^\["([^"]*)"(?:\s*,\s*"([^"]*)")*\]$'
            match = re.match(pattern2, value.strip())
            if match:
                items = re.findall(r'"([^"]*)"', value)
                result = ", ".join(items)
                self.logger.debug(f"Fixed quoted array pattern in {field_name}: {value} -> {result}")
                return result
                
            # Clean up any remaining extra quotes or brackets
            cleaned = value.strip()
            if cleaned.startswith('[') and cleaned.endswith(']'):
                cleaned = cleaned[1:-1].strip()
            if cleaned.startswith('"') and cleaned.endswith('"'):
                cleaned = cleaned[1:-1].strip()
            if cleaned.startswith("'") and cleaned.endswith("'"):
                cleaned = cleaned[1:-1].strip()
                
            return cleaned
            
        # If it's a list, join items with commas
        elif isinstance(value, list):
            # Flatten nested structures and convert to strings
            items = []
            for item in value:
                if isinstance(item, (str, int, float)):
                    items.append(str(item))
                elif isinstance(item, list):
                    # Handle nested lists by flattening
                    nested_items = [str(x) for x in item if isinstance(x, (str, int, float))]
                    items.extend(nested_items)
                else:
                    items.append(str(item))
            
            result = ", ".join(items)
            self.logger.debug(f"Converted array to string in {field_name}: {value} -> {result}")
            return result
            
        # For other types, convert to string
        else:
            result = str(value)
            self.logger.debug(f"Converted {type(value).__name__} to string in {field_name}: {value} -> {result}")
            return result
            
    def _fix_json_content(self, data: Dict[str, Any]) -> Dict[str, str]:
        """Fix JSON content by normalizing all fields to strings.
        
        Args:
            data: Raw JSON data
            
        Returns:
            Fixed JSON data with all string fields
        """
        fixed_data = {}
        
        # Process each required field
        for field in self.required_fields:
            if field in data:
                fixed_data[field] = self._normalize_field_value(data[field], field)
            else:
                fixed_data[field] = ""
                self.logger.warning(f"Missing field '{field}', setting to empty string")
                
        # Handle any extra fields
        for field, value in data.items():
            if field not in self.required_fields:
                fixed_data[field] = self._normalize_field_value(value, field)
                self.logger.info(f"Found extra field '{field}', normalizing")
                
        return fixed_data
        
    def fix_file(self, file_path: Path) -> bool:
        """Fix a single JSON file.
        
        Args:
            file_path: Path to the JSON file to fix
            
        Returns:
            True if fixed successfully, False otherwise
        """
        try:
            self.logger.info(f"Processing {file_path.name}")
            
            # Read the file
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # Parse JSON
            try:
                data = json.loads(content)
            except json.JSONDecodeError as e:
                self.logger.error(f"JSON decode error in {file_path.name}: {e}")
                return False
                
            # Fix the content
            fixed_data = self._fix_json_content(data)
            
            # Write fixed file
            output_path = self.output_dir / file_path.name
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(fixed_data, f, indent=4, ensure_ascii=False)
                
            self.logger.info(f"Fixed and saved: {output_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"Error processing {file_path.name}: {e}")
            return False
            
    def process_directory(self) -> Dict[str, int]:
        """Process all JSON files in the input directory.
        
        Returns:
            Statistics dictionary
        """
        self.logger.info(f"Starting JSON fix process")
        self.logger.info(f"Input directory: {self.input_dir}")
        self.logger.info(f"Output directory: {self.output_dir}")
        
        # Find all JSON files
        json_files = list(self.input_dir.glob("*_keyphrases.json"))
        
        if not json_files:
            self.logger.warning(f"No keyphrase JSON files found in {self.input_dir}")
            return self.stats
            
        self.logger.info(f"Found {len(json_files)} JSON files to process")
        
        # Process each file
        for file_path in json_files:
            self.stats["processed"] += 1
            
            if self.fix_file(file_path):
                self.stats["fixed"] += 1
            else:
                self.stats["failed"] += 1
                
        # Generate summary
        self._generate_summary()
        return self.stats
        
    def _generate_summary(self):
        """Generate and log processing summary."""
        self.logger.info("=" * 50)
        self.logger.info("JSON Fix Processing Summary")
        self.logger.info("=" * 50)
        self.logger.info(f"Files processed: {self.stats['processed']}")
        self.logger.info(f"Files fixed: {self.stats['fixed']}")
        self.logger.info(f"Files failed: {self.stats['failed']}")
        self.logger.info(f"Success rate: {(self.stats['fixed']/self.stats['processed']*100):.1f}%")
        self.logger.info(f"Fixed files saved to: {self.output_dir}")


def main():
    """Main function with command-line interface."""
    parser = argparse.ArgumentParser(
        description="Fix malformed JSON keyphrase files",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Fix files from CVEs/invalid and save to CVEs/fixed
  python json_fix.py

  # Use custom directories
  python json_fix.py --input-dir ./bad_files --output-dir ./good_files

  # Enable debug logging
  python json_fix.py --log-level DEBUG

Common fixes applied:
  - Convert arrays to comma-separated strings
  - Remove extra quotes and brackets
  - Flatten nested structures
  - Normalize field formatting
        """
    )
    
    parser.add_argument(
        "--input-dir",
        default="CVEs/invalid",
        help="Directory containing invalid JSON files (default: CVEs/invalid)"
    )
    
    parser.add_argument(
        "--output-dir", 
        default="CVEs/fixed",
        help="Directory to save fixed JSON files (default: CVEs/fixed)"
    )
    
    parser.add_argument(
        "--log-level",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        default="INFO",
        help="Logging level (default: INFO)"
    )
    
    parser.add_argument(
        "--copy-back",
        action="store_true",
        help="Copy fixed files back to keyphrases directory after fixing"
    )
    
    args = parser.parse_args()
    
    # Initialize fixer
    fixer = JSONFixer(
        input_dir=args.input_dir,
        output_dir=args.output_dir,
        log_level=args.log_level
    )
    
    # Process files
    stats = fixer.process_directory()
    
    # Optionally copy fixed files back
    if args.copy_back and stats["fixed"] > 0:
        print(f"\nCopying {stats['fixed']} fixed files back to CVEs/keyphrases/...")
        keyphrases_dir = Path("CVEs/keyphrases")
        keyphrases_dir.mkdir(parents=True, exist_ok=True)
        
        copied = 0
        for fixed_file in Path(args.output_dir).glob("*_keyphrases.json"):
            dest_path = keyphrases_dir / fixed_file.name
            shutil.copy2(fixed_file, dest_path)
            copied += 1
            
        print(f"Copied {copied} files to CVEs/keyphrases/")
    
    # Final summary
    print(f"\nâœ… JSON fix completed!")
    print(f"ğŸ“Š Processed: {stats['processed']}, Fixed: {stats['fixed']}, Failed: {stats['failed']}")
    print(f"ğŸ“ Fixed files available in: {args.output_dir}")
    
    return 0 if stats["failed"] == 0 else 1


if __name__ == "__main__":
    exit(main())