{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Use camel case for JSON fields\n",
    "\n",
    "in the output json file \n",
    "* use cveId instead of cve_id\n",
    "* impactTexts instead of impact_texts\n",
    "* mitreTechnicalImpacts instead of mitre_technical_impacts\n",
    "\n",
    "    cveId -> \n",
    "    \"cve-id\": \"CVE-2013-0643\",\n",
    "        \"cveId\": \"CVE-2023-28012\",\n",
    "        https://github.com/CVEProject/cvelistV5/blob/9909a609e34af9a8ac85a586e11eee4e7e9a5ed8/cves/2023/28xxx/CVE-2023-28012.json#L5\n",
    "\n",
    "        impact_texts -> impactTexts\n",
    "\n",
    "        mitre_technical_impacts -> mitreTechnicalImpacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 27566 CVE files (only those with keyphrases)\n"
     ]
    }
   ],
   "source": [
    "#only save CVE files that have corresponding keyphrases files\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, Any, List, Tuple, Set\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "def normalize_keyphrases(keyphrases: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Ensure all required fields exist in keyphrases and normalize component fields.\n",
    "    \n",
    "    Args:\n",
    "        keyphrases: Original keyphrases dictionary\n",
    "    \n",
    "    Returns:\n",
    "        Normalized keyphrases dictionary\n",
    "    \"\"\"\n",
    "    required_fields = [\n",
    "        \"rootcause\",\n",
    "        \"weakness\",\n",
    "        \"impact\",\n",
    "        \"vector\",\n",
    "        \"attacker\",\n",
    "        \"product\",\n",
    "        \"version\",\n",
    "        \"component\"\n",
    "    ]\n",
    "    \n",
    "    # Initialize normalized keyphrases\n",
    "    normalized = {}\n",
    "    \n",
    "    # Add all existing fields that don't start with 'component'\n",
    "    for key, value in keyphrases.items():\n",
    "        if not key.startswith('component') or key == 'component':\n",
    "            normalized[key] = value\n",
    "    \n",
    "    # Merge any component-prefixed fields into 'component'\n",
    "    component_values = []\n",
    "    for key, value in keyphrases.items():\n",
    "        if key.startswith('component') and key != 'component':\n",
    "            if isinstance(value, list):\n",
    "                component_values.extend(value)\n",
    "            elif isinstance(value, str) and value:\n",
    "                component_values.append(value)\n",
    "    \n",
    "    # If we found component values, add them to any existing component values\n",
    "    if component_values:\n",
    "        existing_component = normalized.get('component', '')\n",
    "        if isinstance(existing_component, list):\n",
    "            component_values.extend(existing_component)\n",
    "        elif isinstance(existing_component, str) and existing_component:\n",
    "            component_values.append(existing_component)\n",
    "        normalized['component'] = component_values if len(component_values) > 1 else (component_values[0] if component_values else '')\n",
    "    \n",
    "    # Ensure all required fields exist\n",
    "    for field in required_fields:\n",
    "        if field not in normalized:\n",
    "            normalized[field] = \"\"\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def validate_impacts(cve_id: str, keyphrases_impact: Any, impact_texts: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Validate that impactTexts match keyphrases.impact values.\n",
    "    \n",
    "    Args:\n",
    "        cve_id: The CVE identifier\n",
    "        keyphrases_impact: Impact from keyphrases (can be string or list)\n",
    "        impact_texts: List of impact texts from technical_impacts\n",
    "    \n",
    "    Returns:\n",
    "        List of error messages, empty if no errors\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    \n",
    "    # Convert keyphrases impact to list for comparison\n",
    "    if isinstance(keyphrases_impact, str):\n",
    "        keyphrases_impacts = [keyphrases_impact] if keyphrases_impact else []\n",
    "    elif isinstance(keyphrases_impact, list):\n",
    "        keyphrases_impacts = keyphrases_impact\n",
    "    else:\n",
    "        keyphrases_impacts = []\n",
    "    \n",
    "    # Convert to sets for comparison, ignoring empty strings\n",
    "    keyphrases_set = set(filter(None, keyphrases_impacts))\n",
    "    impact_texts_set = set(filter(None, impact_texts))\n",
    "    \n",
    "    # Check for mismatches\n",
    "    if keyphrases_set != impact_texts_set:\n",
    "        extra_in_keyphrases = keyphrases_set - impact_texts_set\n",
    "        extra_in_impacts = impact_texts_set - keyphrases_set\n",
    "        \n",
    "        if extra_in_keyphrases:\n",
    "            errors.append(f\"{cve_id}: Found in keyphrases.impact but not in impactTexts: {extra_in_keyphrases}\")\n",
    "        if extra_in_impacts:\n",
    "            errors.append(f\"{cve_id}: Found in impactTexts but not in keyphrases.impact: {extra_in_impacts}\")\n",
    "    \n",
    "    return errors\n",
    "\n",
    "def get_cves_with_keyphrases(base_dir: str) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Get a set of CVE IDs that have keyphrases files.\n",
    "    \n",
    "    Args:\n",
    "        base_dir: Base directory containing CVE subdirectories\n",
    "    \n",
    "    Returns:\n",
    "        Set of CVE IDs that have keyphrases files\n",
    "    \"\"\"\n",
    "    keyphrases_dir = Path(base_dir) / 'keyphrases'\n",
    "    if not keyphrases_dir.exists():\n",
    "        return set()\n",
    "        \n",
    "    cve_ids = set()\n",
    "    for file_path in keyphrases_dir.glob('CVE-*_*.json'):\n",
    "        cve_id = file_path.name.split('_')[0]\n",
    "        cve_ids.add(cve_id)\n",
    "    \n",
    "    return cve_ids\n",
    "\n",
    "def merge_cve_files(base_dir: str, version: str = \"1.0.0\") -> Tuple[Dict[str, Any], List[str]]:\n",
    "    \"\"\"\n",
    "    Merge JSON files for each CVE ID into a single consolidated structure.\n",
    "    Only includes CVEs that have keyphrases files.\n",
    "    \n",
    "    Args:\n",
    "        base_dir: Base directory containing CVE subdirectories\n",
    "        version: Version string to include in output\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (Dictionary mapping CVE IDs to their consolidated data, List of error messages)\n",
    "    \"\"\"\n",
    "    # First, get the set of CVEs that have keyphrases files\n",
    "    cves_with_keyphrases = get_cves_with_keyphrases(base_dir)\n",
    "    if not cves_with_keyphrases:\n",
    "        return {}, []\n",
    "    \n",
    "    cve_data = {}\n",
    "    error_logs = []\n",
    "    \n",
    "    # Process each type of file\n",
    "    subdirs = ['description', 'keyphrases', 'technical_impacts']\n",
    "    timestamp = datetime.now(pytz.UTC).isoformat()\n",
    "    \n",
    "    for subdir in subdirs:\n",
    "        dir_path = Path(base_dir) / subdir\n",
    "        if not dir_path.exists():\n",
    "            continue\n",
    "            \n",
    "        for file_path in dir_path.glob('CVE-*_*.json'):\n",
    "            cve_id = file_path.name.split('_')[0]\n",
    "            \n",
    "            # Skip if this CVE doesn't have a keyphrases file\n",
    "            if cve_id not in cves_with_keyphrases:\n",
    "                continue\n",
    "            \n",
    "            if cve_id not in cve_data:\n",
    "                # Initialize with metadata\n",
    "                cve_data[cve_id] = {\n",
    "                    \"cveId\": cve_id,\n",
    "                    \"version\": version,\n",
    "                    \"timestamp\": timestamp\n",
    "                }\n",
    "                \n",
    "            with open(file_path, 'r') as f:\n",
    "                file_data = json.load(f)\n",
    "                \n",
    "            # Handle different file types\n",
    "            if 'description' in subdir:\n",
    "                cve_data[cve_id]['description'] = file_data['description']\n",
    "            elif 'keyphrases' in subdir:\n",
    "                # Normalize keyphrases\n",
    "                normalized_keyphrases = normalize_keyphrases(file_data)\n",
    "                cve_data[cve_id]['keyphrases'] = normalized_keyphrases\n",
    "            elif 'technical_impacts' in subdir:\n",
    "                # Store impact_texts temporarily for validation\n",
    "                if 'impact_texts' in file_data:\n",
    "                    cve_data[cve_id]['_temp_impact_texts'] = file_data['impact_texts']\n",
    "                if 'mitre_technical_impacts' in file_data:\n",
    "                    cve_data[cve_id]['mitreTechnicalImpacts'] = file_data['mitre_technical_impacts']\n",
    "    \n",
    "    # Validate impacts and clean up temporary data\n",
    "    for cve_id, data in cve_data.items():\n",
    "        if 'keyphrases' in data and '_temp_impact_texts' in data:\n",
    "            keyphrases_impact = data['keyphrases'].get('impact', '')\n",
    "            impact_texts = data['_temp_impact_texts']\n",
    "            \n",
    "            errors = validate_impacts(cve_id, keyphrases_impact, impact_texts)\n",
    "            error_logs.extend(errors)\n",
    "        \n",
    "        # Remove temporary impact_texts\n",
    "        if '_temp_impact_texts' in data:\n",
    "            del data['_temp_impact_texts']\n",
    "    \n",
    "    return cve_data, error_logs\n",
    "\n",
    "def save_merged_files(cve_data: Dict[str, Any], error_logs: List[str], output_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Save each merged CVE entry as a separate JSON file and error logs.\n",
    "    \n",
    "    Args:\n",
    "        cve_data: Dictionary containing merged CVE data\n",
    "        error_logs: List of error messages\n",
    "        output_dir: Directory to save the output files\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save each CVE as a separate file\n",
    "    for cve_id, data in cve_data.items():\n",
    "        file_path = output_path / f\"{cve_id}.json\"\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    # Save error logs if any\n",
    "    if error_logs:\n",
    "        log_path = output_path / \"impact_validation_errors.log\"\n",
    "        with open(log_path, 'w') as f:\n",
    "            for error in error_logs:\n",
    "                f.write(f\"{error}\\n\")\n",
    "\n",
    "def main():\n",
    "    base_dir = \"CVEs\"\n",
    "    output_dir = \"CVEs/all\"\n",
    "    version = \"1.0.0\"\n",
    "    \n",
    "    # Merge files and get error logs\n",
    "    cve_data, error_logs = merge_cve_files(base_dir, version)\n",
    "    \n",
    "    if not cve_data:\n",
    "        print(\"No CVEs with keyphrases files found. No files will be created.\")\n",
    "        return\n",
    "    \n",
    "    # Save merged files and error logs\n",
    "    save_merged_files(cve_data, error_logs, output_dir)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"Processed {len(cve_data)} CVE files (only those with keyphrases)\")\n",
    "    if error_logs:\n",
    "        print(f\"Found {len(error_logs)} impact validation errors. See impact_validation_errors.log for details\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
