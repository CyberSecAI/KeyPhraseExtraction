name: Test Pipeline

on:
  pull_request:
    branches: [ main ]
    paths:
      - '**.py'
      - 'requirements.txt'
      - '.github/workflows/**'
  
  # Allow manual testing
  workflow_dispatch:
    inputs:
      test_mode:
        description: 'Test mode'
        required: true
        default: 'syntax_only'
        type: choice
        options:
          - syntax_only
          - small_batch
          - full_validation

env:
  PYTHON_VERSION: '3.12'

jobs:
  test-syntax:
    name: Test Python Syntax and Dependencies
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Test Python syntax
      run: |
        echo "Testing Python syntax for all scripts..."
        python -m py_compile keyphraseExtract.py
        python -m py_compile keyphraseExtract_check.py
        python -m py_compile merge_jsons2all.py
        python -m py_compile move2cve_dir_hash.py
        python -m py_compile notebook2python.py
        echo "âœ… All Python files have valid syntax"
        
    - name: Test imports
      run: |
        echo "Testing imports..."
        python -c "
        import sys
        import importlib.util
        
        scripts = [
            'keyphraseExtract.py',
            'keyphraseExtract_check.py', 
            'merge_jsons2all.py',
            'move2cve_dir_hash.py'
        ]
        
        for script in scripts:
            try:
                spec = importlib.util.spec_from_file_location('test_module', script)
                module = importlib.util.module_from_spec(spec)
                # Don't execute, just test if imports work
                print(f'âœ… {script}: Imports successful')
            except Exception as e:
                print(f'âŒ {script}: Import failed - {e}')
                sys.exit(1)
        "
        
    - name: Test command-line interfaces
      run: |
        echo "Testing command-line interfaces..."
        python keyphraseExtract.py --help
        python keyphraseExtract_check.py --help
        python merge_jsons2all.py --help
        echo "âœ… All CLI interfaces working"

  test-small-batch:
    name: Test Small Batch Processing
    runs-on: ubuntu-latest
    if: github.event.inputs.test_mode == 'small_batch' || github.event.inputs.test_mode == 'full_validation'
    needs: test-syntax
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Create test data
      run: |
        mkdir -p test_data/cve_info test_data/cvelistV5_process/data_out
        mkdir -p CVEs/description CVEs/keyphrases CVEs/all logs
        
        # Create minimal test CSV
        cat > test_data/cvelistV5_process/data_out/cve_records_published.csv << EOF
        cve_id,description,state
        CVE-2024-TEST1,"Test buffer overflow vulnerability in example software.",PUBLISHED
        CVE-2024-TEST2,"Cross-site scripting vulnerability in web application.",PUBLISHED
        CVE-2024-TEST3,"SQL injection in database interface.",PUBLISHED
        EOF
        
        echo "Created test data with 3 CVEs"
        
    - name: Test validation pipeline
      run: |
        echo "Testing validation pipeline..."
        
        # Test keyphraseExtract_check with empty directories
        python keyphraseExtract_check.py \
          --input-dir CVEs/keyphrases \
          --cve-info-dir test_data/cve_info \
          --skip-missing-check
          
        echo "âœ… Validation pipeline test completed"
        
    - name: Test merge pipeline
      run: |
        echo "Testing merge pipeline..."
        
        # Create minimal test keyphrase files
        cat > CVEs/keyphrases/CVE-2024-TEST1_keyphrases.json << EOF
        {
          "rootcause": "buffer overflow",
          "weakness": "improper input validation",
          "impact": "arbitrary code execution", 
          "vector": "network",
          "attacker": "remote attacker",
          "product": "example software",
          "version": "1.0",
          "component": "core module"
        }
        EOF
        
        cat > CVEs/description/CVE-2024-TEST1_description.json << EOF
        {
          "description": "Test buffer overflow vulnerability in example software."
        }
        EOF
        
        # Test merge
        python merge_jsons2all.py \
          --base-dir CVEs \
          --output-dir CVEs/all \
          --log-level DEBUG
          
        # Check output
        if [ -f "CVEs/all/CVE-2024-TEST1.json" ]; then
          echo "âœ… Merge pipeline test completed successfully"
          cat CVEs/all/CVE-2024-TEST1.json
        else
          echo "âŒ Merge pipeline test failed"
          exit 1
        fi

  test-full-validation:
    name: Full Validation Test
    runs-on: ubuntu-latest
    if: github.event.inputs.test_mode == 'full_validation'
    needs: [test-syntax, test-small-batch]
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python  
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Test configuration validation
      run: |
        echo "Testing configuration..."
        python -c "
        try:
            from config import GOOGLE_CLOUD_CONFIG, MAIN_MODEL_CONFIG, FALLBACK_MODEL_CONFIG
            print('âœ… Configuration import successful')
            print(f'Google Cloud Project: {GOOGLE_CLOUD_CONFIG.get(\"project_id\", \"Not set\")}')
            print(f'Main Model: {MAIN_MODEL_CONFIG.get(\"model_type\", \"Not set\")}')
            print(f'Fallback Model: {FALLBACK_MODEL_CONFIG.get(\"model_name\", \"Not set\")}')
        except Exception as e:
            print(f'âŒ Configuration error: {e}')
            exit(1)
        "
        
    - name: Test directory structure creation
      run: |
        echo "Testing directory structure..."
        python -c "
        import os
        
        dirs = [
            'CVEs/description',
            'CVEs/keyphrases', 
            'CVEs/all',
            'CVEs/invalid',
            'logs',
            'tmp'
        ]
        
        for d in dirs:
            os.makedirs(d, exist_ok=True)
            if os.path.exists(d):
                print(f'âœ… Created directory: {d}')
            else:
                print(f'âŒ Failed to create directory: {d}')
                exit(1)
        "
        
    - name: Generate test report
      run: |
        echo "# Test Pipeline Report" > test_report.md
        echo "**Date:** $(date -u)" >> test_report.md
        echo "**Python Version:** ${{ env.PYTHON_VERSION }}" >> test_report.md
        echo "**Test Mode:** ${{ github.event.inputs.test_mode || 'syntax_only' }}" >> test_report.md
        echo "" >> test_report.md
        echo "## Test Results" >> test_report.md
        echo "- âœ… Python syntax validation" >> test_report.md
        echo "- âœ… Import testing" >> test_report.md
        echo "- âœ… CLI interface testing" >> test_report.md
        
        if [ "${{ github.event.inputs.test_mode }}" = "small_batch" ] || [ "${{ github.event.inputs.test_mode }}" = "full_validation" ]; then
          echo "- âœ… Small batch processing" >> test_report.md
          echo "- âœ… Validation pipeline" >> test_report.md
          echo "- âœ… Merge pipeline" >> test_report.md
        fi
        
        if [ "${{ github.event.inputs.test_mode }}" = "full_validation" ]; then
          echo "- âœ… Configuration validation" >> test_report.md
          echo "- âœ… Directory structure" >> test_report.md
        fi
        
        echo "" >> test_report.md
        echo "All tests passed successfully! ðŸŽ‰" >> test_report.md
        
    - name: Upload test artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ github.run_number }}
        path: |
          test_report.md
          CVEs/all/
          logs/
        retention-days: 7